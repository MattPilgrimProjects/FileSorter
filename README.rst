Key Music Finder is a completely autonomous program. That means there is no community input or curation that goes into the music analysis. If the AI is wildly wrong, then that is something it needs to acknowledge and do improve in accuracy. The intention of this project is to help understand the structural significance that goes into creating great and memorable tracks. We want to see correlation between multiple songs, from multiple artist from a large range of genres. 
The data collected comprises of entirely MIDI files which are analysed and the results are published to the website. Since this is a automated system, channel recognition is decided by the algorithm. Since the data formation of notes in midi is easier to read, it seemed to have a higher level of accuracy over traditional audio files (although it would be something that is of interest for future projects)
Key Music Finder wants to teach users about that the fundamentals of music in a way that does not tell the user to read note by note the correctly but instead, allow for flexible learning based scales and array of possible chord progressions. It also opens the door to uniquely tailor the characterisation of performance / practice to be more fluid and stylistic to the individual musician. 
We want to expand the system once enough data is collected to find emotions patterns within notation structure and the significance it serves to convey the given “feel” of music. 
The final goal of this project is providing the data accumulated to be used by everyone as an completely open source API . 

